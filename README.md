
## Project Overview
This project aims to classify molecular compounds as "active" or "inactive" using their SMILES representations. The key focus is on comparing two different featurizers: a pre-trained transformer (GPT2-Zinc480M) and a non-pretrained fingerprint vectorizer (SECFP).

The process involves:
1. Loading and preparing the data.
2. Preprocessing SMILES strings into a format suitable for machine learning models.
3. Using different models and featurizers to predict compound activity.
4. Plotting ROC curves to evaluate model performance.

### Key Components
#### 1. Data Preprocessing
- The molecular data is first read from a CSV file using the `get_data()` function. Compounds are labeled as "active" based on a given threshold for pIC50 values. A threshold of 8 is chosen, meaning compounds with a pIC50 greater than 8 are classified as "active." The relevant columns are extracted for further processing.
- **SMILES Preprocessing**: SMILES strings, which describe the molecular structure, undergo sanitization and standardization before being used as input to the model. This is handled using functions from the **datamol** library.

#### 2. Feature Transformation
- Two types of featurizers are applied to the preprocessed SMILES:
  - **GPT (Pretrained Transformer)**: Uses a pre-trained GPT-like model (GPT2-Zinc480M-87M) to convert SMILES strings into feature vectors for training.
  - **SECFP (Fingerprint Vector)**: Uses SECFP fingerprints to generate feature vectors.
  These transformations are performed using functions from the **molfeat** library.

#### 3. Model Training and Evaluation
- Due to the small dataset size, we consider two simple models:
  - **Logistic Regression (LR)**: A regularized logistic regression model with grid search for tuning the regularization strength (C parameter).
  - **Random Forest (RF)**: A model with hyperparameters `n_estimators` and `max_depth` tuned using a grid search.
  
- **Cross-Validation**: The combination of models and featurizers is evaluated using cross-validation:
  - **StratifiedKFold** is used to ensure balanced data splits. Cross-validation is applied both on the validation set to tune hyperparameters and on the test set to evaluate model performance.
  
- The results are visualized using ROC curves, showing the trade-off between the True Positive Rate (TPR) and False Positive Rate (FPR). The mean ROC curve, as well as the variability in ROC performance across folds, is plotted.

### Key Decisions
1. **Preprocessing and Featurizers**: **datamol** and **molfeat** were chosen for their ease of integration with the **sklearn** library.
2. **Featurizer Choice**:
   - **GPT2-Zinc480M** was selected for its potential to create rich molecular representations through pretraining.
   - **SECFP** serves as a reliable baseline.
3. **Model Selection**:
   - **Logistic Regression (LR)**: Given that the feature representations may be rich, a simple linear model is likely sufficient due to the limited number of observations.
   - **Random Forest (RF)**: Chosen for its stability as a non-linear classifier, we aim to explore if non-linear classification improves performance over linear models.
4. **Evaluation Methodology**:
   - **ROC AUC Metric**: AUC is used to compare different models and featurizers because it summarizes the trade-off between false positives and false negatives across all probability thresholds.
   - In practice, both false positives (predicting a molecule is active when it isnâ€™t) and false negatives (predicting inactivity when the molecule is active) have different implications. Therefore, users can use the ROC curve to select the optimal probability threshold based on their needs.

### Code Structure
1. utils.py contains the following functions:
   - **get_data()**: Loads data from a CSV file, applies a threshold to define "active" molecules, and returns a DataFrame with relevant columns.
   _preprocess()
   - **prepare_data()**: Converts the SMILES strings into feature vectors using the featurizer, and returns the features (X) and labels (y).
   - **get_model_performance()**: Performs cross-validation on the models using ROC AUC as the evaluation metric.
   Plots the mean ROC curve, as well as its variability to visualize model performance.

2. main_analysis.ipynb contains the main analysis script that runs the model training using configurations defined within the notebook.